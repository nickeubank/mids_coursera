{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Data Values to Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a perfect world, our datasets would all arrive containing only accurate data formatted in exactly the way we need. Sadly, the world we live in is *not* perfect. Either because of clumsy data entry, bad translation between data formats, survey participations trying to be jerks, or the coding errors of other data scientists, messy data is a fact of life. As a result, a key part of being a data scientist is to learn to (a) seek out and identify data cleanliness problems, and (b) learn to correct them. These parts of data science are not nearly as cool or widely discussed as new machine learning packages or the latest learning algorithm, but as anyone who has done data science in the real world will tell you, cleaning (plus merging and reshaping, which we'll cover soon) will take up the *vast* majority of your working life. So in this lesson, we'll talk about tools in `pandas` for identifying and correcting problems with your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Problems\n",
    "\n",
    "Everything I said above may sound... well, awful, but here's the good news: once you get into it, data cleaning begins to feel less like grunt work and more like being a detective, and it can actually be a lot of fun. In some of the examples below, I'll be showing you problems in small toy datasets where you can easily see the problems with the data just by looking at the dataset. In real data, however, things aren't so easy -- when your data has hundreds of thousands of rows, or where data errors are subtle, learning to find and isolate problems can actually be quite fun and challenging! \n",
    "\n",
    "Here are a few helpful functions we can demonstrate with our old friend the American Community Survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "acs = pd.read_stata(\"https://github.com/nickeubank/MIDS_Data/blob/master/US_AmericanCommunitySurvey/US_ACS_2017_10pct_sample.dta?raw=true\")\n",
    "acs = acs[['year', 'sex', 'age', 'inctot', 'empstat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First is `.sample()`: while it's tempting to use `.head()` to look at the top of your data, it's usually more valuable to look at a random sample of rows, since data is usually sorted so the first rows are unlikely to be representative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>inctot</th>\n",
       "      <th>empstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166590</th>\n",
       "      <td>2017</td>\n",
       "      <td>male</td>\n",
       "      <td>62</td>\n",
       "      <td>170000</td>\n",
       "      <td>employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207895</th>\n",
       "      <td>2017</td>\n",
       "      <td>female</td>\n",
       "      <td>6</td>\n",
       "      <td>9999999</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214500</th>\n",
       "      <td>2017</td>\n",
       "      <td>male</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>not in labor force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28863</th>\n",
       "      <td>2017</td>\n",
       "      <td>female</td>\n",
       "      <td>less than 1 year old</td>\n",
       "      <td>9999999</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18280</th>\n",
       "      <td>2017</td>\n",
       "      <td>female</td>\n",
       "      <td>11</td>\n",
       "      <td>9999999</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year     sex                   age   inctot             empstat\n",
       "166590  2017    male                    62   170000            employed\n",
       "207895  2017  female                     6  9999999                 n/a\n",
       "214500  2017    male                    18        0  not in labor force\n",
       "28863   2017  female  less than 1 year old  9999999                 n/a\n",
       "18280   2017  female                    11  9999999                 n/a"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.random as npr\n",
    "npr.seed(42) # Setting a seed so we get the same results\n",
    "             # every time I run this notebook so \n",
    "             # I can write about what what we see\n",
    "             # and that won't change. \n",
    "acs.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See? Already we can see some weird values in `inctot` (9999999), and that ages cover quite a wide range, and that there are some `n/a` values in `empstat`. \n",
    "\n",
    "We can also use `.describe()`. When using `describe()`, look in particular at the maximum and minimum values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inctot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.190040e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.723646e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.732326e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.050000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.370000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.140000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999999e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             inctot\n",
       "count  3.190040e+05\n",
       "mean   1.723646e+06\n",
       "std    3.732326e+06\n",
       "min   -9.000000e+03\n",
       "25%    1.050000e+04\n",
       "50%    3.370000e+04\n",
       "75%    9.140000e+04\n",
       "max    9.999999e+06"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the `max` value is INSANELY large, and so is probably not a real value, and we can see there are crazy negative values too, which are probably also some kind of code, not a real value. Those negative values are not something we way in our sample above, so we need to check on those!\n",
    "\n",
    "We also see that `age` is not plotted by `describe()`, which tells us it's not being read as a number but rather a string, something else we need to address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, we can use `.value_counts()` to see all the possible values of certain variables, like `empstat`. Note that you can pass `dropna=False` as an option to get counts of missing values too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employed              148758\n",
       "not in labor force    104676\n",
       "n/a                    57843\n",
       "unemployed              7727\n",
       "Name: empstat, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs.empstat.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting -- so now we know that the variable has a `n/a` category, but no values `pandas` recognizes as missing (e.g. `np.nan`), so we'll have to clean those up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, it's really good to plot your data. As we discussed before in our plotting exercises, many distributions of data look the same when we calculate summary statistics, but plotting can be super helpful in showing us when things are wrong. Remember how both of these distributions have the same correlations, mean values, and standard devaiations?\n",
    "\n",
    "![dino_plot_scatter](images/dino_plot_scatter.png)![dino_plot_dino](images/dino_plot_dino.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, if we want to be more formal about it, we can also see the famous Anscombe's Quartet of distributions with the same linear regression fits:\n",
    "\n",
    "![anscombes_quartet](images/anscombes_quartet.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
