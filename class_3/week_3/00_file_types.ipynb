{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways To Store and Read Data\n",
    "\n",
    "Central to the life of the data scientist is, well, data! At this point you are already well on your way to being an expert in manipulating data once you have loaded it into Python, but we haven't talked very much about the various formats in which data may be given to you as files. So in this reading we will talk about the three main families of data files you are likely to encounter, their pros and their cons, and how to work with them. These three families are:\n",
    "\n",
    "1. Plaintext files: files that store data as text. These are files that you could easily open up in a text editor and read yourself, making them very flexible and robust.\n",
    "2. Binary files: files that have processed your data prior to storage. Reading and writing data from these files tends to be faster, and these files will tend to take up less space on your computer, but you can't easily open them up and look at them, and you need the right software to access them.\n",
    "3. Databases: databases aren't (usually) individual files, but rather software that collectively manages a collection of datasets in one places, and manages access to different datasets. These are the systems people are referring to when they talk about \"SQL Databases\". We won't get into these here, but you should be aware that you can access SQL databases through Python and pandas. \n",
    "\n",
    "Below is an introduction to both Plaintext and Binary file formats, as well as an overview of how to work with them and considerations for which to use. **Don't worry about trying to memorize everything that follows, however!** The world of data formats is kinda like a zoo, and if you try and memorize every fact on the plaques in front of every exhibit you'll go insane. Instead, the goal is to give you a sense of what's out there and to make sure you understand the two big types of data files (plaintext and binary) you may come across. For all the specifics, our goal is just to give you enough familiarity that you know what to Google when you come across these files on the wild!\n",
    "\n",
    "## Plaintext Files\n",
    "\n",
    "For all the advancements that have been made in sophisticated data storage formats, plaintext files remain the most common data format you are likely to encounter. That's because plaintext file store data as—as the name suggests—plain text! As a result there is very little that can go wrong with data stored in this format—any computer that knows how to read a text file can open plaintext data, meaning no one has to worry about whether future data users or colleagues will have the right version of the right software to read the data. \n",
    "\n",
    "Indeed, nearly all of the data that we've used in this specialization has been stored in plaintext files. The US Income Data we worked with in Class 2 Week 2, for example, came from a file called `us_household_incomes.txt`, where `.txt` is a file suffix that just tells the computer the file is a \"text\" file. Indeed, if I open up the file in VS Code (instead of trying to read it into Python), it looks like this:\n",
    "\n",
    "![US Household Incomes Opened As Text](img/us_household_incomes_as_text.png)\n",
    "\n",
    "Note both that the contents are easily readable—each line is the income of a single house that, when read into numpy, becomes one entry in a vector—and also that VS Code recognizes it as Plain Text, and displays that in the bottom right.\n",
    "\n",
    "And what exactly does it mean that the file can be opened in any text editor and read? It means that at the level of the 1s and 0s that make up the file, numbers and letters are encoded using simple, commonly used encodings (like [ASCII](https://en.wikipedia.org/wiki/ASCII) or [Unicode](https://en.wikipedia.org/wiki/Unicode). These files also do not contain anything complicated (pictures, media, etc.), and in fact don't even include information like fonts, or formatting. \n",
    "\n",
    "This simplicity makes plaintext files (nearly) universally compatible, and easy to work with, so are a favorite of programmers. Indeed, any code you've ever written in a file has almost surely been saved as a plaintext file too!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Plaintext Data\n",
    "\n",
    "When it comes to the type of tabular data that we are working with in this course (data organized into rows and columns), there are two main plaintext formats, and a handful of descendants to be aware of:\n",
    "\n",
    "- **Comma Separated Values** (CSVs): plaintext files that use the file suffix `.csv`. In these files, each row of text represents one row in the data, and columns are separated by commas. \n",
    "- **Tab Separated Values** (TSVs): plaintext files that usually use the file suffix `.txt` or, less commonly, `.tsv`. In these files, each row of text represents one row in the data, and columns are separated by tabs (the special character denoting an indentation).\n",
    "- **Plaintext tabular data with other separators:** In addition to these two formats, one *can* also create plaintext tabular files using basically any character to separate the columns, such as semi-colons, spaces, or anything else. These are a little bit unusual, but since it's possible you will come across them in life we just wanted to mention that they exist! Note that there is no standard file suffix when using these other separators, so these types of files will just end up with a `.csv` or `.txt` file suffix.\n",
    "\n",
    "Of these, CSVs are by far the most used, in part I suspect because tabs are often an invisible character, sometimes making it hard to see where one column ends and the next ends when looking at the file as text. A small CSV, by contrast, can be pretty easy to read (or at least get a sense of). Here, for example, is what a small CSV file looks like when I open it in VS Code:\n",
    "\n",
    "![Small CSV in VS Code](img/world_v_small.png)\n",
    "\n",
    "Across the top are our column names, and each row below contains one row of data (one observation). Note that unlike in, say, Excel, the columns of a CSV won't necessarily line up (unless by chance all the entries in a column are of the same size). \n",
    "\n",
    "Moreover, in CSVs, you will notice that entries in columns that are meant to be read as text will often—though not always—be enclosed in quotation marks (in this CSV, the second column uses quotation marks but the first does not, despite both being text). In theory you don't need them, but if you have data—like names written `LAST NAME, FIRST NAME`—that contain commas in the data itself, the quotation marks are required so your computer knows which commas separate columns and which are data.\n",
    "\n",
    "By the way, to make CSVs easier to read, there's a great little extension in VS Code called [Rainbow CSV](https://marketplace.visualstudio.com/items?itemName=mechatroner.rainbow-csv) that will assign a color to all data in each CSV column. These colors aren't in the file itself—VS Code is parsing the CSV and adding the colors after the file has been opened:\n",
    "\n",
    "![Small CSV in VS Code with Rainbow Coloring](img/world_v_small_w_rainbow.png)\n",
    "\n",
    "And indeed, if we wanted to read this into pandas, we could do so easily with `pd.read_csv`, and we'd get the table we expect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>gdppcap08</th>\n",
       "      <th>polityIV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>S. America</td>\n",
       "      <td>10296</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>W. Europe</td>\n",
       "      <td>35613</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>N. America</td>\n",
       "      <td>14495</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>Africa</td>\n",
       "      <td>855</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russia</td>\n",
       "      <td>C&amp;E Europe</td>\n",
       "      <td>16139</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>C&amp;E Europe</td>\n",
       "      <td>7271</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country      region  gdppcap08  polityIV\n",
       "0      Brazil  S. America      10296        18\n",
       "1     Germany   W. Europe      35613        20\n",
       "2      Mexico  N. America      14495        18\n",
       "3  Mozambique      Africa        855        16\n",
       "4      Russia  C&E Europe      16139        17\n",
       "5     Ukraine  C&E Europe       7271        16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"data/world-very-small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Tabular Plaintext Data\n",
    "\n",
    "While CSVs and tab separated value files are the most common way to pass around tabular data in plaintext files, there's one other plaintext data format that is become increasingly popular: JSON.\n",
    "\n",
    "Unlike CSVs or TSVs, which can *only* be used for tabular data (data arranged in rows and columns), JSON files *can* store tabular data, but are designed to be much more flexible. In particular, JSON files can store both dictionaries (more formally called \"key-value pairs\") and lists. Moreover, just like Python lists and dictionaries, lists and dictionaries stored in JSON files can be *nested*, meaning you can put dictionaries that contain other dictionaries that contain lists that contain dictionaries etc. in a JSON file. \n",
    "\n",
    "To illustrate, let's make a simple dictionary and Python and save it to a JSON file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pets': ['dogs', 'cats'], 'wild animals': ['zebras', 'penguins']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_dict = {\"pets\": [\"dogs\", \"cats\"], \"wild animals\": [\"zebras\", \"penguins\"]}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ask the `json` module from the Python standard library to convert our dictionary into a JSON string. If we wanted to save our dictionary to a file, we would just save the string to a text file with the file suffix `.json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"pets\": [\n",
      "        \"dogs\",\n",
      "        \"cats\"\n",
      "    ],\n",
      "    \"wild animals\": [\n",
      "        \"zebras\",\n",
      "        \"penguins\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Print out what the json\n",
    "# representation of our dictionary would look like.\n",
    "# Note that `indent=4` results in \n",
    "# this nice looking indentation—without that option\n",
    "# the contents all appear on one line.  \n",
    "print(json.dumps(my_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's a pretty human-readable format: it uses `:` to separate dictionary keys from values (just like Python), and puts lists in `[]` pairs (just like Python). \n",
    "\n",
    "And while it isn't really *built* for tabular data (it's a kind inefficient way to write a table compared to CSVs), JSON can be used to store tabular data. For example, here's what we get if I load our small CSV table from above, exported to a JSON file, and then open it up and VS Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"data/world-very-small.csv\")\n",
    "\n",
    "# Export to JSON\n",
    "df.to_json(\"data/world-very-small.json\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![json of small world](img/world_v_small_json.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Exporting Plaintext Tabular Data\n",
    "\n",
    "Another really good news: pandas makes working with all of these forms of tabular data trivially easy! Here's all you need to read or write these different types of tabular data:\n",
    "\n",
    "**Reading:**\n",
    "\n",
    "- **Read a CSV:** `df = pd.read_csv(\"path/to/file.csv\")`\n",
    "- **Read a TSV:** `df = pd.read_csv(\"path/to/file.txt\", sep=\"\\t\")`. Note this is still `read_csv`, just now with `\\t` specified as the separator. Indeed, you can load any [symbol] Separated Value plaintext file with `pd.read_csv`, just change out the `sep` argument!\n",
    "- **Read JSON:** `df = pd.read_json(\"path/to/file.json\")`. Note that this can be a little finicky depending on how the JSON file is formatted. If the format is simple: the JSON file contains a dictionary, where each entry has a column name as a key and a list with the contents of the column, it works easily. If not you may need to use some of the [additional keyword arguments](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html).\n",
    "\n",
    "**Writing:**\n",
    "\n",
    "- **Write a CSV:** `df.write_csv(\"path/to/file.csv\")`\n",
    "- **Write a TSV:** `df.write_csv(\"path/to/file.csv\", sep=\"\\t\")`\n",
    "- **Write to JSON:** `df.write_json(\"path/to/file.json\")`\n",
    "\n",
    "And that's really all there is to it for most files! \n",
    "\n",
    "Or... it should be. But from time you'll run into odd formatting issues, or dates stored oddly, or strange character, or other anomalies. If that does happen to you, however, should be aware of is that the pandas `pd.read_csv` function is one of **the** most impressive functions you will find anywhere in the Python ecosystem in terms of the number of inbuilt utilities it offers. And to see that, all you have to do is look at the function documentation. Seriously, go take a look at all the options [the function offers in the official documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). It can read zipped or compressed CSVs, it can automatically handle different symbols being used to separate decimal values, it can remove commas used in big numbers, it can process dates in any format, it can drop columns while loading data, it can ignore certain rows, you can add column names by hand, the options just go on and on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Files\n",
    "\n",
    "The second major type of data file you are likely to come across are binary files. This is a data format that is not easily human-readable, and which you will only be able to open if you have the appropriate software. Binary files sometimes come from proprietary software (like Microsoft Excel), but there are also a range of open-source binary file standards. Here are a handful:\n",
    "\n",
    "**Formats Created By Proprietary Software:**\n",
    "\n",
    "- `.xls`, `.xlsx`: Excel spreadsheets. Excel can open and save `.csv` files, but by default it stores data in `.xlsx` formats that can also store formatting information, functions, etc. \n",
    "    - Read with `pd.read_excel` and write with `pd.write_excel`.\n",
    "- `.dta`: Binary data files created by the program [Stata](https://en.wikipedia.org/wiki/Stata). \n",
    "    - Read with `pd.read_stata` and write with `pd.write_stata`.\n",
    "- `.sav`: Binary data files created by the program [SPSS](https://en.wikipedia.org/wiki/SPSS). \n",
    "    - Read with `pd.read_spss` and write with `pd.write_spss`.\n",
    "\n",
    "**Open Standards:**\n",
    "\n",
    "- [Parquet](https://en.wikipedia.org/wiki/Apache_Parquet): Created by the Apache Foundation, Parquet is increasingly my *personal* favorite file format. It was originally designed to aid with distributed computer (e.g. using lots of computers to process very large datasets), but also works great with smaller data. \n",
    "    - Read with `pd.read_parquet` and write with `pd.write_parquet`.\n",
    "- [Pickle](https://docs.python.org/3/library/pickle.html): Pickle is a format for saving Python objects. It is not only Python specific, but there are also a few different versions of pickle that have been released over the years, and pickle files are often not backwards compatible. Moreover, you should never open a pickle file you don't trust as they are a great vector for malware. \n",
    "- [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format): A slightly older binary format that I think was first popularized by astronomers looking to store lots of image data. Kinda hard to work with though, not recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So What File Format Should I Use?\n",
    "\n",
    "All this raises the obvious question: what format should YOU use when saving your own data?\n",
    "\n",
    "Generally speaking, if you're saving data for yourself or a colleague, I would suggest a binary format like parquet or a Stata dta file. Using a binary format ensures that when you load your data again later, pandas doesn't struggle to figure out if a column is a string or a number, and parquet in particular will compress your data so you don't use up more space than necessary, and will write and re-open very quickly.\n",
    "\n",
    "But if you're disseminating data widely or to people whose technical abilities you aren't sure about, a plaintext format will almost surely cause fewer problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e0a5228cb9726a24d36227c69ed0d3aac98cecda769d1c9adb080711d57f90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
