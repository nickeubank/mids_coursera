{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Arrays: The Workhorse of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time has come for us to introduce the workhorse that makes nearly all data science in Python possible: the `numpy` `array`.\n",
    "\n",
    "Like the lists and dictionaries we've already seen, arrays are an object for collecting and organizing lots of individual records -- what's sometimes referred to as a *collection*. Unlike lists and dictionaries, however, which can store nearly anything you want to put into them, arrays are *homogeneously typed*, meaning that each array is designed to store a specific type of data, and can *only* store that type of data. An array of integers, for example, can only store integers, and an array of floating point numbers can only hold floating point numbers. \n",
    "\n",
    "While this may initially seem like it makes arrays inferior to more flexible collections, like lists, there is a major upside: this specialization makes arrays *fast* -- as in orders of magnitude faster -- and it is this speed that makes data science in Python possible.\n",
    "\n",
    "And as we'll see in future readings, arrays make possible a style of programming called *vectorized programming* that not only tends to be very fast, but also makes the kind of programming we do a lot in data science especially concise and easy-to-read. And if you know any linear algebra, you'll also see that this way of programming results in code that looks more like the math of linear algebra, which many data scientists find really appealing.\n",
    "\n",
    "Arrays come in many forms, but there are two specific types of arrays whose names will be familiar: when an array organizes its data along a single dimension, we call it a *vector*, and when its data is organized along two dimensions (like how data is laid out in an Excel spreadsheet), we call it a *matrix*. \n",
    "\n",
    "Most of the time when doing data science, these are actually the only two kinds of arrays you are likely to encounter, and so they will be the focus of the following several readings. However, as we'll see towards the end of this course, there isn't really anything different about working with arrays in three, four, or more dimensions; everything you learn in these first few lessons will generalize easily to all arrays. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using numpy\n",
    "\n",
    "In past lessons, we saw that not all Python functionality is accessible when you first start a Python session -- some functionality is located in libraries we have to import to use. For example, in a previous module, we used the command `import [something Drew and Geneview imported]` to gain access to functions for [something or other]. \n",
    "\n",
    "Numpy basically works the same way -- we can gain access to its functionality by typing `import numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "numpy.array([1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are two things that are a little different about numpy from the libraries we've used before. \n",
    "\n",
    "First, numpy is what's called a *third-party library*, meaning that you don't automatically get it when you install Python. Instead, you have install the numpy library before it can be used. numpy has already been installed in the version of Python you have access to here on coursera, but if you are working with Python on another computer, you'll need to install it using a tool like `pip` or `conda` -- we have a reading on installing third party packages here [we'll need obviously!].\n",
    "\n",
    "Second, because we will be working with numpy a lot, we don't want to have to type out `numpy.` every time we access a numpy function. Instead, it is common practice to give numpy as alias (a different name) by typing: `import numpy as np`. Once we do that, we can access functions from the numpy library with the prefix `np.` instead of `numpy.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([1, 2, 3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we know how to access the functionality of numpy, let's turn to using it to create vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a30e2",
   "metadata": {},
   "source": [
    "## The Speed of numpy\n",
    "\n",
    "As noted above, one of the main reasons that numpy is the foundation of data science in Python is that it does numerical computations incredibly efficiently in the sense that it is both fast and good at not using up all of your computer's memory. In a later lesson we'll talk more about the exact reasons that numpy is so fast, but before we dive in to learning numpy, it's worth taking a moment to illustrate just how impressive numpy is!\n",
    "\n",
    "To illustrate, let's create a list with all the numbers from one to one hundred million and sum them up. We will do this twice -- once using regular Python tools, and once using numpy. Don't worry about the fact that some of the code that I use isn't familiar yet -- we will learn all of these numpy tool soon -- the goal is just to give you a basic demonstration of why were going through the trouble of learning this library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd4b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a regular Python list\n",
    "# with all the numbers up to one hundred million\n",
    "\n",
    "# Remember `range` doesn't include the last number,\n",
    "# so I have to go up to 100_000_001 to actually get all\n",
    "# the numbers from 1 to 100_000_000\n",
    "\n",
    "one_to_one_hund_mil_list = list(range(1, 100_000_001))\n",
    "\n",
    "# Now make a numpy vector\n",
    "# with all the numbers up to one hundred million\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "one_to_one_hund_mil_vector = np.arange(1, 100_000_001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed096680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.19 s, sys: 56.5 ms, total: 8.25 s\n",
      "Wall time: 8.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000000050000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Add up all the numbers in a normal Python loop\n",
    "# (the %%time just asks a special program to time\n",
    "# the execution of this code)\n",
    "\n",
    "total = 0\n",
    "for i in one_to_one_hund_mil_list:\n",
    "    total = total + i\n",
    "    pass\n",
    "\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97bdfaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 113 ms, sys: 3.26 ms, total: 116 ms\n",
      "Wall time: 114 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000000050000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Now we sum up all the numbers in the array\n",
    "# using the numpy `sum` function.\n",
    "np.sum(one_to_one_hund_mil_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee42353",
   "metadata": {},
   "source": [
    "So on my 2019 Macbook Pro, that took about 8 seconds with regular Python; ~0.1 seconds with numpy. That's a ~75x speedup, just for that simple calculation. (We could get this to run more quickly by using the regular Python `sum()` function instead of writing our own loop, but even then numpy would be about ~10x faster.)\n",
    "\n",
    "But that's not all -- regular Python required *much* more memory to store its list of numbers than was required by numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "\n",
    "# `asizeof.asizeof()` gets the size of an object\n",
    "# and all of its contents in Bytes.\n",
    "\n",
    "list_size_in_gb = asizeof.asizeof(one_to_one_hund_mil_list) / 1_000_000_000\n",
    "vector_size_in_gb = asizeof.asizeof(one_to_one_hund_mil_vector) / 1_000_000_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python list of numbers took up 4.00 GB of RAM\n",
      "The numpy vector of numbers took up 0.80 GB of RAM\n",
      "That means the Python list took up 5x as much space as the numpy vector!\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Python list of numbers took up {list_size_in_gb:.2f} GB of RAM\")\n",
    "print(f\"The numpy vector of numbers took up {vector_size_in_gb:.2f} GB of RAM\")\n",
    "print(\n",
    "    f\"That means the Python list took up {list_size_in_gb/vector_size_in_gb:.0f}x as much space as the numpy vector!\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bb7e0",
   "metadata": {},
   "source": [
    "This is, of course, a toy example; if all we wanted to do is data scientists was some up the contents of a couple vectors, it wouldn't be worth learning numpy just to save eight seconds. But of course that's *not* what we do in data science -- we work with data sets that not only have millions of rows, but also hundreds or thousands of columns. And we're not just trying to sum them up; we are inverting and multiplying full matrices over and over, and running millions of calculations to calculate derivatives and evaluate objective functions. As a result, even with numpy, we are often doing tasks that take minutes, hours, or days. If we had to do that with vanilla Python, those same tasks would take hours, days, or even weeks or months, and that's assuming you could even find a way to load your data given how much more memory vanilla Python requires to store data.\n",
    "\n",
    "And so *that* is why we are learning numpy!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e0a5228cb9726a24d36227c69ed0d3aac98cecda769d1c9adb080711d57f90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
