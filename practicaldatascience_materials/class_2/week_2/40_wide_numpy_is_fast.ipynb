{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4a30e2",
   "metadata": {},
   "source": [
    "## Why Do We Need Vectors? \n",
    "\n",
    "\"If vectors are *basically* like lists, except that they can only store data of one type, why on earth do we need them?\" I hear you asking.\n",
    "\n",
    "Speed and memory usage.\n",
    "\n",
    "As we mentioned in our last reading, lists are flexible, but that flexibility comes at the cost of performance and memory usage. In other words, if lists and cars were vehicles, lists would be 18 wheelers -- lots of space to store stuff, but big and hard to get around -- and numpy vectors would be sports cars -- small and fast, not much storage.\n",
    "\n",
    "How much slower? Well, to illustrate let's create a list with all the numbers from one to a billion and sum them with regular Python; then let's do the same thing with numpy vectors and compare the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remember `range` doesn't include the last number,\n",
    "# so I have to go up to 1_000_000_001 to actually get all\n",
    "# the numbers from 1 to 1_000_000_000\n",
    "\n",
    "# Make list\n",
    "one_to_billion_list = list(range(1, 1_000_000_001))\n",
    "\n",
    "# May array\n",
    "one_to_billion_vector = np.arange(1, 1_000_000_001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed096680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 s, sys: 35.8 s, total: 47.7 s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000000500000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time sum(one_to_billion_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bdfaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 5.95 s, total: 7.72 s\n",
      "Wall time: 10.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500000000500000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time np.sum(one_to_billion_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee42353",
   "metadata": {},
   "source": [
    "So on my 2019 Macbook Pro with 32GB RAM, that took about ~1 minute with regular Python; ~10 seconds with numpy. That's more than a 50x speedup, just for that simple calculation.\n",
    "\n",
    "But that's not all -- to create that list, regular Python required over **35GB** of RAM, while numpy only used about 6GB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4bb7e0",
   "metadata": {},
   "source": [
    "This is, of course, a toy example. But storing large collections of numbers and manipulating them quickly is at the heart of data science, and these differences in speed and storage efficiency are precisely why we use numpy arrays instead of regular Python objects like lists. \n",
    "\n",
    "But why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Memory\n",
    "\n",
    "When most of us think about computer memory, we just think of it as a kind of amorphous place where stuff is getting \"put\" in some mysterious sense. But the reality is that memory is actually a physical thing in our computer, and a big part of why Python and numpy have such different performance characteristics is related to how they use that physical resource. \n",
    "\n",
    "Let's begin by imagining your computer memory is divided into two parts -- a \"stack\", which is like small book you have right in front of you, and a \"heap\", which is like a big field laid out in front of you. This heap is just a big field of buckets, each of which is capable of holding an individual 1 or 0, and each of which has an address. \n",
    "\n",
    "Now supposed you want to know what number is associated with, say, the variable `x` in Python. What you have to do is look in the book in front of you (the stack) and find the page for `x`, where you'll find an address. Then you have to walk out to the field, find the buckets at that address, and read out the contents.\n",
    "\n",
    "Now, by the standards of computers, that process of going out to the heap takes a *huge* amount of time. As a result, a big part of making programs faster involves minimizing the number of times your computer has to get an address, go out to memory, and look at what's out there. \n",
    "\n",
    "Indeed, in many computer programs when you assign a number like `1` to `x`, instead of writing down the *address* where that 1 can be found next to `x` in the stack, they just write they number 1. But not in Python! In Python *all* data is stored in the heap.\n",
    "\n",
    "(I know, I know -- if you've taken a course on computer architecture, I'm sure this analogy is *deeply* offensive to your deeper understanding of how all this works, but bear with me). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
