{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Module Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Crack the cipher!\n",
    "Ciphers have been a way of keeping messages secret for centuries, one of the most famous being the Caesar cipher. Your task here is to write a decoding function to decode an encoded message. The encoded message is shown below. Each character from the original message is looked up in `plain` and replaced with the corresponding character in `cipher`. For example. The number `0` would be replaced with the letter `j` and the number `1` would be replaced with the letter `w`.\n",
    "\n",
    "**(1)** Create a function `decode_message` and determine the decoded version of the encoded message.\n",
    "\n",
    "**(2)** Create a function `encode_message` and determine the encoded version of the phrase `'the chamber of secrets'`. Use the same cipher. What is the encoded message?\n",
    "\n",
    "*Hint*: You should be able to test your pair of functions - if you encode, then decode a message, you should get back the original message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_message = 'eQyo8Qno5nogKM9z3IA03I1KMi'\n",
    "\n",
    "plain  = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ '\n",
    "cipher = 'jwCRPYqc6uHvmFED8T5pxNLZQ4OtbnydSr273BgXkJ9s1Gf0UMKWhziIA Vaelo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Pascal's Triangle Revisited\n",
    "Recall the Pascal Triangle Question from Quiz 2 (revisit Quiz 2 Part 3 for more information on Pascal's Triangle).\n",
    "\n",
    "Recall that we can index the first few rows of Pascal's triangle as follows:\n",
    "\n",
    "```\n",
    "row 0:     1\n",
    "row 1:    1 1\n",
    "row 2:   1 2 1 \n",
    "row 3:  1 3 3 1 \n",
    "row 4: 1 4 6 4 1 \n",
    "```\n",
    "\n",
    "**(3)** How many of the values in row 250 (where we call the first row, 'row 0', as shown above) of Pascal's Triangle are multiples of 99?\n",
    "\n",
    "**(4)** What is the median value in row 50 of Pascal's Triangle?\n",
    "\n",
    "*Note: assuming your Pascal Triangle code works correctly from Quiz 2, this should require very little additional code*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Energy data revisited\n",
    "Recall Quiz 3's dataset - this builds on that dataset further, so the introduction to the dataset is included here as well. The `data` folder contains a file called, `egrid2016.xlsx`. This is the dataset we'll be exploring through these exercises. This dataset is the Environmental Protection Agency's (EPA) [Emissions & Generation Resource Integrated Database (eGRID)](https://www.epa.gov/energy/emissions-generation-resource-integrated-database-egrid) containing information about all power plants in the United States, the amount of genereration they produce, what fuel they use, the location of the plant, and many more quantities. We'll be using a subset of those data.\n",
    "\n",
    "The fields we'll be using include:\t\t\t\t\t\n",
    "    \n",
    "|field    |description|\n",
    "|:-----   |:-----|\n",
    "|SEQPLT16 |eGRID2016 Plant file sequence number (the index)| \n",
    "|PSTATABB |Plant state abbreviation|\n",
    "|PNAME    |Plant name |\n",
    "|LAT      |Plant latitude |\n",
    "|LON      |Plant longitude|\n",
    "|PLPRMFL  |Plant primary fuel |\n",
    "|CAPFAC   |Plant capacity factor |\n",
    "|NAMEPCAP |Plant nameplate capacity (Megawatts MW)|\n",
    "|PLNGENAN |Plant annual net generation (Megawatt-hours MWh)|\n",
    "|PLCO2EQA |Plant annual CO2 equivalent emissions (tons)|\n",
    "\n",
    "For more details on the data, you can refer to the [eGrid technical documents](https://www.epa.gov/sites/production/files/2018-02/documents/egrid2016_technicalsupportdocument_0.pdf). For example, you may want to review page 45 and the section \"Plant Primary Fuel (PLPRMFL)\", which gives the full names of the fuel types including WND for wind, NG for natural gas, BIT for Bituminous coal, WAT for hydroelectric, etc.\n",
    "\n",
    "### Your questions about this dataset\n",
    "\n",
    "**(5)** What state has the largest total capacity (in MW) of natural gas power plants?\n",
    "\n",
    "**(6)** What state has the largest net generation (in MWh) of hydroelectric power plants? \n",
    "\n",
    "**(7)** Carbon intensity is the amount of CO2 emitted per unit energy generated. So if a power plant emitted 200 tons of CO2 to generate 1000 MWh, then it's carbon intensity would be 200/1000 = 0.2 tons/MWh. This number can be seen as a measure of how carbon intensive the energy generated in a given state is. Which state is the LEAST carbon intensive?\n",
    "\n",
    "**(8)** Following up on the last question - which state is the MOST carbon intensive?\n",
    "\n",
    "**(9)** Capacity factor is a measure of the fraction of the year the plant is running at it's rated capacity (MW). Plants of which fuel type of fuel have the highest median capacity factor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Plotting a matrix and smoothing data\n",
    "Often raw data are noisy, containing both the information we want plus some random values added on top that we refer to as noise. In this exercise, you'll uncover a hidden message in image data that has been obscured by noise. \n",
    "\n",
    "One technique to reduce the impact of noise on data is smoothing. Here, we'll create a moving average filter to smooth the data. A moving average filter calculates the average over a subset of data (for example, just the first $N$ values at a time) and to smooth the day, that 'window' moves along the data series from the beginning to the end.\n",
    "\n",
    "The figure below illustrates how a moving average works for a window length of $N=3$.\n",
    "\n",
    "<img src='./img/moving_average.png'>\n",
    "\n",
    "You can see that the output values vary noticeably less  than the input values, since the outliers in the data have been \"smoothed\" towards the average. Also notice that the output is a DIFFERENT length than the input. This is because the window needs to be able to overlap the data, so the output will be necessarily smaller than the input for window lengths greater than 1.\n",
    "\n",
    "Create your own function to implement a 1-D moving average that takes the window length, $N$, as an input. You can use the above example in the image above to verify that your moving average function is working.\n",
    "\n",
    "Your goal here is to uncover the obscured message in an image using smoothing. The image can be found in the `data` folder, and is titled `obscured_image.png`. Start by plotting the image to see the original data. You'll notice it looks like a lot of random values, without any meaningful pattern. \n",
    "\n",
    "To smooth the image to reveal the hidden message - first take the moving average of each of the rows of the image matrix to create a new matrix composed of the smoothed rows. Next take the moving average of the columns of that new matrix and create yet another new matrix from the smoothed columns. For each case, use a smoothing window size of $N=11$. Once you've completed this, you should be able to see the hidden message when you plot the image.\n",
    "\n",
    "Now in reality, for this situation you would typically take a 2-dimensional moving average and it may even by a weighted moving average. That's for a more advanced image processing or computer vision course. This exercise, however, provides you with experience working with image matrices, smoothing data, and visualizing the results.\n",
    "\n",
    "**(10)** What is the message encoded in the image?\n",
    "\n",
    "*Getting started hint: you'll want to use the scipy ndimage.imread function to load the image. This is good practice for learning how to use new functions. Use the import statement: `import scipy.ndimage as ndimage`, then you can use `ndimage.imread` function to load the image.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
